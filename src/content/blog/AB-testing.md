---
title: "Three A/B Tests That Changed How We Grow"
excerpt: "Small experiments, big lessons. How tiny product changes helped us increase conversions, boost engagement, and better understand our users at Atom Learning."
date: "2025-02-02"
image: "/lovable-uploads/AB Testing.png"
category: "Portfolio"
slug: "ab-testing-growth"
---

# Three A/B Tests That Changed How We Grow: Lessons from Atom Learning

If you're working on a growing product, it’s easy to fall into the habit of chasing big swings. A homepage redesign. A viral campaign. A pricing overhaul. But sometimes the most impactful shifts come from tiny tweaks — words, positions, buttons — backed by clear hypotheses and careful measurement.

As Product Manager of Growth at Atom Learning, I was responsible for improving how parents and teachers discover, evaluate, and adopt our platform. That often meant diving into the messy middle: where user intent meets product friction. A/B testing was one of our most powerful tools.

In this post, I’ll walk through three A/B tests we ran — what we tested, what we learned, and how it shaped our growth strategy.

---

## 1. Where the CTA Lives: Visibility > Persuasion

**Test:** We wanted to increase free trial signups from our main landing page. Our existing page had a clean layout, but the primary CTA ("Start your free trial") sat below the fold, underneath a block of explanatory copy.

**Hypothesis:** Moving the CTA above the fold would increase visibility, and with it, conversion.

**Setup:**

- **A (Control):** CTA below paragraph intro  
- **B (Variant):** CTA top-right, sticky on scroll, with a condensed version also appearing on mobile

**Results:**

![CTA Conversion Chart](/lovable-uploads/cta_chart.png)

> The variant showed a **53% increase in clicks** and a **46% increase in trial conversions**. It wasn’t the copy that needed changing — it was the *placement*.

> _“People weren’t ignoring our message. They just weren’t seeing it.”_

**Takeaway:** Design hierarchy matters. Don't bury the lead. We rolled this change out across other marketing pages and eventually into our onboarding experience, ensuring key actions were always visible.

---

## 2. Headline Framing: Functional vs. Emotional Value

When launching a new parent dashboard feature, we wanted to test how different value propositions would resonate. One approach emphasized *efficiency*, the other emphasized *ease and empowerment*.

**Hypothesis:** Emotional framing would drive more engagement than time-saving framing.

**Setup:**

- **A:** “Save hours every week with Atom’s new dashboard”  
- **B:** “Stay in control of your child’s learning — without the overwhelm”

We tested this messaging in our announcement banner, email campaigns, and onboarding tooltips.

**Results:**

![Headline Chart](/lovable-uploads/headline_chart.png)

**Takeaway:** Parents already felt short on time — but what they craved was *clarity and confidence*. Emotional resonance outperformed logical value. We applied this to future email campaigns and landing pages, shifting away from productivity language toward emotional benefit.

---

## 3. The Personal Touch: Re-engaging Cold Users

Atom’s free trial period gave parents a taste of the product before deciding to convert. But many users became inactive after a few logins. We ran an A/B test on subject lines for our re-engagement email.

**Hypothesis:** A personalized, curiosity-driven subject line would outperform a generic reminder.

**Setup:**

- **A:** “Your Atom Learning Trial Ends Soon”  
- **B:** “Luke, still thinking about Year 6 prep?”

**Results:**

![Email Chart](/lovable-uploads/email_chart.png)

**Takeaway:** The second version performed **28% better on open rate** and **41% better on re-activations**. Personalization didn’t just work — it scaled. This success led us to build out a more robust CRM strategy with dynamic content and tailored triggers.

---

## What These Tests Taught Me

1. **Data beats intuition — but only when paired with empathy.**  
   All three of these tests started from qualitative insights. Heatmaps, interviews, drop-off flows. The hypotheses weren’t pulled from thin air — they came from paying attention.

2. **Micro-changes create macro-impact.**  
   None of these experiments were redesigns. But together, they helped us improve signup rate, feature adoption, and trial re-engagement — compounding growth over time.

3. **You can’t optimize what you don’t measure.**  
   We used Mixpanel for activation tracking, VWO for A/B testing, and a custom-built dashboard for cohort-based retention analysis. That toolkit let us move fast, with confidence.

---

## Final Thoughts

A/B testing isn’t just about lifting metrics — it’s about learning. Each test gives you a sharper sense of your user, a better intuition for your product, and a clearer lens for prioritization.

At Atom, these experiments helped us stay focused on what mattered: reducing friction, reinforcing value, and turning good intentions into actual outcomes. We didn’t always get it right. But every test gave us an edge.

If you're building something — especially something for parents, students, or educators — small changes can teach you big things.
